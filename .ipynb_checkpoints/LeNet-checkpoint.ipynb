{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains a CNN that attempts to classify MNIST digits, similar to Yann LeCun's LeNet-5 (http://www.dengfanxin.cn/wp-content/uploads/2016/03/1998Lecun.pdf). I built a custom TensorFlow Estimator to explore how the high-level API works. Some code from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/layers/cnn_mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 description from https://github.com/sujaybabruwad/LeNet-in-Tensorflow/blob/master/LeNet-Lab.ipynb\n",
    "\n",
    "# Input\n",
    "\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "# Architecture\n",
    "\n",
    "**Layer 1:** Convolutional. The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2:** Convolutional. The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using tf.contrib.layers.flatten.\n",
    "\n",
    "**Layer 3:** Fully Connected. This should have 120 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 4:** Fully Connected. This should have 84 outputs.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Layer 5:** Fully Connected (Logits). This should have 10 outputs (one for each digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network that determines MNIST digit from image\n",
    "# Three Conv/Pool Layers followed by two FC layers and logits\n",
    "def lenet_fn(features, labels, mode):\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 32, 32, 1])\n",
    "    \n",
    "    # Convolutional Layer #1\n",
    "    # Computes 28 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 32, 32, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 6]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=6,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"valid\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 6]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 6]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 16 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 6]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 16]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=16,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 3\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 16]\n",
    "    # Output Tensor Shape: [batch_size, 5, 5, 16]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=3)\n",
    "    \n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 5, 5, 16]\n",
    "    # Output Tensor Shape: [batch_size, 5 * 5 * 16]\n",
    "    pool2_flat = tf.contrib.layers.flatten(pool2)\n",
    "    \n",
    "    # Dense Layer #1\n",
    "    # Densely connected layer with 120 neurons\n",
    "    # Input Tensor Shape: [batch_size, 5 * 5 * 16]\n",
    "    # Output Tensor Shape: [batch_size, 120]\n",
    "    dense1 = tf.layers.dense(inputs=pool2_flat, units=120, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Dense Layer #2\n",
    "    # Densely connected layer with 84 neurons\n",
    "    # Input Tensor Shape: [batch_size, 120]\n",
    "    # Output Tensor Shape: [batch_size, 84]\n",
    "    dense2 = tf.layers.dense(inputs=dropout1, units=84, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=dense2, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 84]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout2, units=10)\n",
    "    \n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for training\"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the read end of the pipeline.\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "train, test = tf.keras.datasets.mnist.load_data()\n",
    "train_images, train_labels = train\n",
    "test_images, test_labels = test\n",
    "\n",
    "# MNIST images are 28x28 but LeNet accepts 32x32, so let's pad the images with 0s\n",
    "train_images = np.pad(train_images, ((0,0), (2,2), (2,2)), 'constant')\n",
    "test_images = np.pad(test_images, ((0,0), (2,2), (2,2)), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 1, 2, 2, 4, 3, 6, 8, 2, 6, 2, 3, 4, 4, 1, 1, 1, 4, 7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's print some random digits and their labels\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "label_array = []\n",
    "for i in range(1, columns*rows+1):\n",
    "    randomNum = random.randint(0,55000)\n",
    "    label_array.append(train_labels[randomNum])\n",
    "    image = train_images[randomNum]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(image, cmap=\"gray_r\")\n",
    "plt.show()\n",
    "print(label_array)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Tyler\\AppData\\Local\\Temp\\tmpziqot_8y\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_session_config': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E0A4E00E80>, '_master': '', '_tf_random_seed': None, '_task_type': 'worker', '_num_ps_replicas': 0, '_log_step_count_steps': 100, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_train_distribute': None, '_model_dir': 'C:\\\\Users\\\\Tyler\\\\AppData\\\\Local\\\\Temp\\\\tmpziqot_8y', '_task_id': 0, '_save_checkpoints_steps': None, '_evaluation_master': '', '_save_checkpoints_secs': 600}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1093\u001b[0m                                        \u001b[0mskip_bound_arg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1094\u001b[1;33m                                        sigcls=Signature)\n\u001b[0m\u001b[0;32m   1095\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2161\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2162\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{!r} is not a callable object'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <tf.Tensor 'IteratorGetNext:0' shape=(?, 32, 32) dtype=uint8> is not a callable object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c9722d1ff0c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     hooks=[logging_hook])\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Evaluate the model and print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    841\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    845\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    851\u001b[0m       features, labels, input_hooks = (\n\u001b[0;32m    852\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[1;32m--> 853\u001b[1;33m               input_fn, model_fn_lib.ModeKeys.TRAIN))\n\u001b[0m\u001b[0;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    689\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_and_labels_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m     \u001b[1;31m# TODO(anjalisridhar): What about the default DistributionStrategy? Perhaps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;31m# using any input is alright in that case. There is also a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    787\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minput_fn\u001b[0m \u001b[0mtakes\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0marguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \"\"\"\n\u001b[1;32m--> 789\u001b[1;33m     \u001b[0minput_fn_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'mode'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_fn_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\util.py\u001b[0m in \u001b[0;36mfn_args\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_callable_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m       \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_bounded_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'self'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[0mdecorators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   return next((d.decorator_argspec for d in decorators\n\u001b[1;32m---> 90\u001b[1;33m                if d.decorator_argspec is not None), spec_fn(target))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tyler\\anaconda3\\envs\\tensorflow\\lib\\inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;31m# else. So to be fully backwards compatible, we catch all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m         \u001b[1;31m# possible exceptions here, and reraise a TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unsupported callable'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported callable"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(model_fn=lenet_fn)\n",
    "\n",
    "# Set up logging for predictions\n",
    "# Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "# Train the model\n",
    "train_input = input_fn(train_images, train_labels, BATCH_SIZE)\n",
    "\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input,\n",
    "    steps=20000,\n",
    "    hooks=[logging_hook])\n",
    "\n",
    "# Evaluate the model and print results\n",
    "eval_input = input_fn(test_images, test_labels, BATCH_SIZE)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
